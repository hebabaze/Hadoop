Step 1 — Installing Java
	1. sudo apt-get install default-jdk
	2. java -version

Step 2 — Installing Hadoop
	3.sudo wget https://downloads.apache.org/hadoop/common/hadoop-3.2.1/hadoop-3.2.1.tar.gz
	4.sudo tar zxvf hadoop-* -C /usr/local
	5. sudo mv /usr/local/hadoop-* /usr/local/hadoop

Step 3 :  Configure environment
	6.sudo nano ~/.bashrc
    I.Add the following path variables in it (verify ur java Path in first line)
		#HADOOP VARIABLES START
		export JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64/ 
		export HADOOP_INSTALL=/usr/local/hadoop
		export PATH=$PATH:$HADOOP_INSTALL/bin
		export PATH=$PATH:$HADOOP_INSTALL/sbin
		export HADOOP_MAPRED_HOME=$HADOOP_INSTALL
		export HADOOP_COMMON_HOME=$HADOOP_INSTALL
		export HADOOP_HDFS_HOME=$HADOOP_INSTALL
		export YARN_HOME=$HADOOP_INSTALL
		export HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_INSTALL/lib/native
		export HADOOP_OPTS="-Djava.library.path=$HADOOP_INSTALL/lib"
		#HADOOP VARIABLES END
# Load configure
	7.source ~/.bashrc
	8.cd /usr/local/hadoop/etc/hadoop
	8. ls
	
	9. sudo nano hadoop-env.sh
  #define Java Path 
    verify path with command : $ readlink -f /usr/bin/java | sed "s:bin/java::"
    II.Add line :(Java path )
	    export JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64/  
	    
	10. sudo nano core-site.xml
    III. add Lines :
	
	<configuration>
	<property>
	  <name>fs.default.name</name>
	    <value>hdfs://localhost:9000</value>
	</property>
	</configuration>
 
       12. sudo nano hdfs-site.xml

  VI.Add lines :
	<configuration>
	<property>
	 <name>dfs.replication</name>
	 <value>1</value>
	</property>
	<property>
	  <name>dfs.name.dir</name>
	    <value>file:///home/hadoop/hadoopdata/hdfs/namenode</value>
	</property>
	<property>
	  <name>dfs.data.dir</name>
	    <value>file:///home/hadoop/hadoopdata/hdfs/datanode</value>
	</property>
	</configuration>

	13 .sudo nano  mapred-site.xml

  V.Add Lines:
	<configuration>
	<property>
	<name>mapreduce.framework.name</name>
	<value>yarn</value>
	</property>
	</configuration>

	14. sudo nano yarn-site.xml
 VI.Add lines :
	<configuration>
	 <property>
	  <name>yarn.nodemanager.aux-services</name>
	    <value>mapreduce_shuffle</value>
	 </property>
	</configuration>
Step 4 :Start the cluster
	15.sudo chmod 777 -R /usr/local/hadoop/
	16. hdfs namenode -format
	17 start-dfs.sh
	18 start-yarn.sh
	19 jps
	
...
